{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Graph Embeddings (Node2Vec)\n",
    "\n",
    "This notebook generates Node2Vec embeddings for the Elliptic++ dataset.\n",
    "\n",
    "**Steps:**\n",
    "1. Load Elliptic++ dataset with temporal splits\n",
    "2. Generate Node2Vec embeddings per split (no leakage)\n",
    "3. Save embeddings with txId mapping\n",
    "\n",
    "**Output:** `data/embeddings.parquet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "from src.data.elliptic_loader import EllipticDataset\n",
    "from src.data.verify_dataset import verify_dataset\n",
    "from src.embeddings.node2vec import generate_node2vec_embeddings\n",
    "from src.utils.seed import set_all_seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config\n",
    "with open('../configs/embed_node2vec.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "set_all_seeds(config['seed'])\n",
    "print(f\"Config loaded: {config['experiment']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify dataset\n",
    "data_root = Path(config['data']['root'])\n",
    "success, messages = verify_dataset(data_root)\n",
    "for msg in messages:\n",
    "    print(msg)\n",
    "\n",
    "if not success:\n",
    "    raise FileNotFoundError(\"Dataset incomplete - please provide all required files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset = EllipticDataset(data_root, use_local_only=True)\n",
    "print(f\"Dataset loaded with {len(dataset.features_df)} nodes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings (split-aware to prevent leakage)\n",
    "n2v_config = config['node2vec']\n",
    "\n",
    "# For each split, generate embeddings using only within-split edges\n",
    "all_embeddings = []\n",
    "\n",
    "for split_name in ['train', 'val', 'test']:\n",
    "    print(f\"\\n=== Generating embeddings for {split_name} ===\")\n",
    "    \n",
    "    features, labels, edge_index_split = dataset.get_split_data(split_name)\n",
    "    \n",
    "    # Convert to torch\n",
    "    edge_index_t = torch.from_numpy(edge_index_split).long()\n",
    "    \n",
    "    # Generate embeddings\n",
    "    embeddings = generate_node2vec_embeddings(\n",
    "        edge_index=edge_index_t,\n",
    "        num_nodes=len(features),\n",
    "        embedding_dim=n2v_config['embedding_dim'],\n",
    "        walk_length=n2v_config['walk_length'],\n",
    "        context_size=n2v_config['context_size'],\n",
    "        walks_per_node=n2v_config['walks_per_node'],\n",
    "        p=n2v_config['p'],\n",
    "        q=n2v_config['q'],\n",
    "        epochs=config['training']['epochs'],\n",
    "        device=config['device']\n",
    "    )\n",
    "    \n",
    "    all_embeddings.append(embeddings)\n",
    "\n",
    "# Concatenate all splits\n",
    "full_embeddings = pd.concat(all_embeddings, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save embeddings with txId\n",
    "embeddings_df = pd.DataFrame(\n",
    "    full_embeddings,\n",
    "    columns=[f'emb_{i}' for i in range(n2v_config['embedding_dim'])]\n",
    ")\n",
    "embeddings_df.insert(0, 'txId', dataset.features_df['txId'])\n",
    "\n",
    "output_path = Path(config['output']['save_path'])\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "embeddings_df.to_parquet(output_path, index=False)\n",
    "\n",
    "print(f\"\\nâœ… Embeddings saved to {output_path}\")\n",
    "print(f\"   Shape: {embeddings_df.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
